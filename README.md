<h1 align="center">Hi üëã, I'm Abdarrahmane AS-SAIDI</h1>
<h3 align="center">üë®‚Äçüíª Final year Cybersecurity Engineering Student üîí Passionate about all things IT </h3> 
<!-- <p align="right"> <img src="https://komarev.com/ghpvc/?username=abdarrahmaneas-saidi&label=Profile%20views&color=0e75b6&style=flat" alt="abdarrahmaneas-saidi" /> </p> -->

Currently, I'm pursuing a FINAL-YEAR INTERNSHIP at HPS, gaining hands-on experience in securing digital infrastructures. I have a strong foundation in networks, system administration, scripting, virtualization, cloud, AI and cybersecurity best practices.

üöÄ My goal: To design and implement cutting-edge security solutions as a Cybersecurity Architect. Always eager to learn and grow in the world of technology.

Let's connect! Feel free to check out my projects and collaborate on cybersecurity innovations:

<a href="https://linkedin.com/in/abdarrahmane-as-saidi"><img src="https://img.shields.io/badge/-LinkedIn-0072b1?&style=for-the-badge&logo=linkedin&logoColor=white" /></a>

## Skills

| Skill                                         | Associated Project         |
|-----------------------------------------------|----------------------------|
| To be listed          | <a href="https://google.com">Building a Comprehensive SOC</a>|
| To be listed | <a href="https://google.com">Building a SECURE Infrastructure</a>|

## Tools
<div align="center">
  <a href="https://skillicons.dev">
    <img src="https://skillicons.dev/icons?i=python,javascript,c,java,mysql,r,go,raspberrypi,docker,aws,azure,terraform,bash,elasticsearch,grafana,kafka,kubernetes,linux,ubuntu,windows,nginx,powershell,prometheus,redhat,tensorflow" /> </br>Other Tools To be listed... </a>
</div>

## Certifications
- To be listed
<div>
<!-- <img src="https://img.shields.io/badge/-Security%2B-FF0000?&style=for-the-badge&logo=CompTIA&logoColor=white" /> -->
</div>

## Projects
- Building a Comprehensive SOC (Documentation in Progress)
- Building a SECURE Infrastructure (Documentation in Progress)



# TP1  AI

Pour accomplir cette t√¢che, nous devons impl√©menter quatre fonctions principales pour √©valuer les co√ªts et gradients pour la r√©gression lin√©aire et logistique. Ces fonctions utiliseront les conventions de forme mentionn√©es et des manipulations vectorielles pour √©viter les boucles, en utilisant la biblioth√®que NumPy. Voici les fonctions √† impl√©menter :

1. **Fonction de co√ªt des moindres carr√©s** (`mean_squared_error`)
2. **Fonction de co√ªt de la r√©gression logistique** (`logistic_regression`)
3. **Gradient des moindres carr√©s** (`mean_squared_error_gradient`)
4. **Gradient de la r√©gression logistique** (`logistic_regression_gradient`)

### Impl√©mentation du Code

### 1. Fonction `mean_squared_error`

Pour cette fonction, on calcule l'erreur quadratique moyenne (MSE) comme suit :
\[ \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - X_i \cdot b)^2 \]

```python
import numpy as np

def mean_squared_error(b, x, y):
    predictions = x.dot(b)  # Pr√©dictions lin√©aires
    errors = y - predictions  # Erreur entre pr√©dictions et labels
    mse = np.mean(errors ** 2)  # Moyenne des carr√©s des erreurs
    return mse

```

### 2. Fonction `logistic_regression`

Pour la r√©gression logistique, la fonction de co√ªt est d√©finie par :
\[ J(b) = \frac{1}{n} \sum_{i=1}^{n} \log(1 + e^{-y_i \cdot (X_i \cdot b)}) \]

```python
def logistic_regression(b, x, y):
    logits = x.dot(b)  # Logits : produit matriciel de X et b
    cost = np.mean(np.log(1 + np.exp(-y * logits)))  # Co√ªt logistique
    return cost

```

### 3. Gradient `mean_squared_error_gradient`

Le gradient pour la MSE est donn√© par :
\[ \nabla_{\text{MSE}} = -\frac{2}{n} X^T \cdot (y - X \cdot b) \]

```python
def mean_squared_error_gradient(b, x, y):
    predictions = x.dot(b)  # Pr√©dictions
    errors = y - predictions  # Erreur
    gradient = -2 * x.T.dot(errors) / len(y)  # Gradient
    return gradient

```

### 4. Gradient `logistic_regression_gradient`

Pour la r√©gression logistique, le gradient est :
\[ \nabla_{\text{Logistique}} = -\frac{1}{n} X^T \cdot \left(\frac{y}{1 + e^{y \cdot (X \cdot b)}}\right) \]

```python
def logistic_regression_gradient(b, x, y):
    logits = x.dot(b)
    probabilities = 1 / (1 + np.exp(y * logits))  # Sigmo√Øde invers√©e pour le gradient
    gradient = -x.T.dot(y * probabilities) / len(y)
    return gradient

```

### V√©rification des Fonctions

Utilisez `check_fonctions()` pour tester les fonctions en suivant les assertions propos√©es.

```python
def check_fonctions():
    np.random.seed(0)
    datax = np.random.randn(1000, 2)
    datay = np.random.choice([-1, 1], size=(1000, 1))
    b_random = np.random.randn(datax.shape[1], 1)

    mse_value = mean_squared_error(b_random, datax, datay)
    assert np.isclose(mse_value, 1.59701, rtol=1e-4), f"Erreur MSE attendue: {mse_value}"

    lr_value = logistic_regression(b_random, datax, datay)
    assert np.isclose(lr_value, 0.75698, rtol=1e-4), f"Erreur logistique attendue: {lr_value}"

    mse_grad_value = mean_squared_error_gradient(b_random, datax, datay)
    assert np.isclose(mse_grad_value.mean(), 0.70793, rtol=1e-4), f"Gradient MSE moyen attendu: {mse_grad_value.mean()}"

    lr_grad_value = logistic_regression_gradient(b_random, datax, datay)
    assert np.isclose(lr_grad_value.mean(), 0.07050, rtol=1e-4), f"Gradient logistique moyen attendu: {lr_grad_value.mean()}"

    print("Toutes les fonctions ont pass√© les tests.")

check_fonctions()

```

Ces impl√©mentations suivent les instructions pour √©viter les boucles en utilisant des op√©rations matricielles et vectorielles optimis√©es avec NumPy, tout en respectant les formes et conventions de dimensions donn√©es pour √©viter des erreurs lors de l‚Äôex√©cution.

Voici l'impl√©mentation des deux fonctions demand√©es :

1. **`gradient_check`** : pour v√©rifier l'exactitude du calcul de gradient.
2. **`gradient_descent`** : pour optimiser une fonction de co√ªt via la descente de gradient.

### 1. Impl√©mentation de `gradient_check`

Cette fonction utilise la m√©thode des diff√©rences finies pour approximer le gradient num√©riquement, puis compare ce gradient num√©rique avec le gradient analytique fourni par `fn_grad`.

```python
import numpy as np

def gradient_check(fn, fn_grad, N=100, epsilon=1e-5):
    np.random.seed(0)

    # G√©n√©rer des points de donn√©es et des cibles al√©atoires
    datax = np.random.randn(N, 2)
    datay = np.random.randn(N, 1)
    b = np.random.randn(datax.shape[1], 1)

    # Calculer le gradient analytique
    analytic_grad = fn_grad(b, datax, datay)

    # Calculer le gradient num√©rique
    numeric_grad = np.zeros_like(b)

    for i in range(b.shape[0]):
        b_plus = b.copy()
        b_plus[i] += epsilon
        f_plus = fn(b_plus, datax, datay)

        b_minus = b.copy()
        b_minus[i] -= epsilon
        f_minus = fn(b_minus, datax, datay)

        numeric_grad[i] = (f_plus - f_minus) / (2 * epsilon)

    # V√©rifier la similarit√© entre le gradient analytique et le gradient num√©rique
    if np.all(np.isclose(analytic_grad, numeric_grad, atol=1e-5)):
        print("Le gradient analytique et le gradient num√©rique sont proches pour tous les points.")
    else:
        print("Il y a une diff√©rence notable entre le gradient analytique et le gradient num√©rique.")

    return analytic_grad, numeric_grad

```

### 2. Impl√©mentation de `gradient_descent`

La fonction `gradient_descent` optimise les param√®tres en utilisant la descente de gradient. Elle met √† jour les param√®tres √† chaque it√©ration en fonction du gradient, puis stocke les valeurs de param√®tres et de la fonction de co√ªt pour chaque √©tape.

```python
def gradient_descent(datax, datay, fn_loss, fn_grad, eps=0.01, num_iterations=1000):
    # Initialisation al√©atoire des param√®tres
    b = np.random.randn(datax.shape[1], 1)
    b_values = [b.copy()]
    loss_values = [fn_loss(b, datax, datay)]

    for i in range(num_iterations):
        grad = fn_grad(b, datax, datay)
        b = b - eps * grad  # Mise √† jour des param√®tres avec le pas de descente
        b_values.append(b.copy())
        loss_values.append(fn_loss(b, datax, datay))  # Calcul du co√ªt √† chaque it√©ration

        # Afficher la progression toutes les 100 it√©rations
        if i % 100 == 0:
            print(f"It√©ration {i}: Co√ªt = {loss_values[-1]}")

    return b, b_values, loss_values

```

### Explication des Fonctions :

1. **`gradient_check`** :
    - Elle g√©n√®re des points de donn√©es al√©atoires et des cibles, puis compare le gradient analytique au gradient num√©rique obtenu par diff√©rences finies.
    - Elle utilise `np.isclose` avec une tol√©rance de `1e-5` pour v√©rifier si les gradients sont proches.
2. **`gradient_descent`** :
    - Elle initialise al√©atoirement les param√®tres `b`, puis r√©alise `num_iterations` it√©rations de mise √† jour du gradient.
    - Elle stocke les param√®tres et les valeurs de la fonction de co√ªt √† chaque √©tape, ce qui permet de tracer ou de v√©rifier la convergence apr√®s l‚Äôex√©cution.

### Exemple d'utilisation

Pour v√©rifier les fonctions `mean_squared_error` et `mean_squared_error_gradient`, nous pourrions ex√©cuter :

```python
# V√©rification du gradient pour la fonction de co√ªt MSE
gradient_check(mean_squared_error, mean_squared_error_gradient)

# Optimisation de la fonction de co√ªt MSE
b_optimal, b_history, loss_history = gradient_descent(datax, datay, mean_squared_error, mean_squared_error_gradient, eps=0.01, num_iterations=1000)

```

Ces fonctions devraient fournir des informations sur la progression et la convergence, et `gradient_check` permettra de confirmer la pr√©cision des gradients calcul√©s analytiquement.
